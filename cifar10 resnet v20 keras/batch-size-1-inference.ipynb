{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import uff\n",
    "import tensorrt as trt\n",
    "import ctypes\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from six.moves import cPickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference(context, h_input, d_input, h_output, d_output, stream):\n",
    "    # Transfer input data to the GPU.\n",
    "    cuda.memcpy_htod_async(d_input, h_input, stream)\n",
    "    # Run inference.\n",
    "    inference_success = context.execute_async(bindings=[int(d_input), int(d_output)], stream_handle=stream.handle)\n",
    "    # Transfer predictions back from the GPU.\n",
    "    cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
    "    # Synchronize the stream\n",
    "    stream.synchronize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate host and device buffers, and create a stream.\n",
    "def allocate_buffers(engine):\n",
    "    # Determine dimensions and create page-locked memory buffers (i.e. won't be swapped to disk) to hold host inputs/outputs.\n",
    "    h_input = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(0)), dtype=trt.nptype(trt.float32))\n",
    "    h_output = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(1)), dtype=trt.nptype(trt.float32))\n",
    "    # Allocate device memory for inputs and outputs.\n",
    "    d_input = cuda.mem_alloc(h_input.nbytes)\n",
    "    d_output = cuda.mem_alloc(h_output.nbytes)\n",
    "    # Create a stream in which to copy inputs/outputs and run inference.\n",
    "    stream = cuda.Stream()\n",
    "    return h_input, d_input, h_output, d_output, stream\n",
    "\n",
    "def mAP(y_true, y_pred):\n",
    "    \n",
    "    y_true = np.array(labels).astype(np.int64)\n",
    "    y_true = tf.identity(y_true)\n",
    "\n",
    "    y_pred = np.array(y_pred).astype(np.float32)\n",
    "    y_pred = tf.identity(y_pred) # np to tensor\n",
    "    _, m_ap = tf.metrics.average_precision_at_k(y_true, y_pred, 1)\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    tf_map = sess.run(m_ap)\n",
    "    return tf_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR10_dataset(file_name):\n",
    "    with open(file_name, 'rb') as f:                \n",
    "        d = cPickle.load(f)\n",
    "        # decode utf8\n",
    "        d_decoded = {}\n",
    "        for k, v in d.items():\n",
    "            d_decoded[k.decode('utf8')] = v\n",
    "        d = d_decoded\n",
    "        data = d['data']\n",
    "        labels = d['labels']\n",
    "        raw_float_data = np.array(data, dtype=float) / 255.0\n",
    "        return raw_float_data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-0807e9c161f4>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-0807e9c161f4>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    engine.\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def inference(cifar_file_name, trt_engine):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.ERROR)\n",
    "    results = np.zeros((10000, 10))\n",
    "    with trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        with open(trt_engine, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "            engine = runtime.deserialize_cuda_engine(f.read())\n",
    "            engine.max_batch_size\n",
    "            h_input, d_input, h_output, d_output, stream = allocate_buffers(engine)\n",
    "            with engine.create_execution_context() as context:\n",
    "                # Reshape the array to 4-dimensions.\n",
    "                print(engine.max_batch_size)\n",
    "                imgs, labels = load_CIFAR10_dataset(cifar_file_name)\n",
    "                processed_imgs = imgs.reshape([-1, 3, 32, 32]).astype(trt.nptype(trt.float32))\n",
    "                t0 = time.time()\n",
    "                for i in range(0, len(processed_imgs)):\n",
    "                    np.copyto(h_input, processed_imgs[i].ravel())\n",
    "                    do_inference(context, h_input, d_input, h_output, d_output, stream)\n",
    "                    #print(h_output.size)\n",
    "                    results[i] = np.transpose(np.array(h_output))\n",
    "                    #print(np.argmax(h_output))\n",
    "                t1 = time.time()     \n",
    "                total_t = t1-t0 \n",
    "                print(\"total time: \" + str(total_t))\n",
    "                return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#FP 32\n",
    "cifar_file = \"/home/vtpc/Documents/Alvils/tensorrt/cifar-10-batches-py/test_batch\"\n",
    "engine_file = \"fp32.engine\"\n",
    "imgs, labels = load_CIFAR10_dataset(cifar_file)\n",
    "\n",
    "results = inference(cifar_file, engine_file)\n",
    "pred = mAP(labels, results)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INT 8\n",
    "cifar_file = \"/home/vtpc/Documents/Alvils/tensorrt/cifar-10-batches-py/test_batch\"\n",
    "engine_file = \"int8.engine\"\n",
    "results = inference(cifar_file, engine_file)\n",
    "pred = mAP(labels, results)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
