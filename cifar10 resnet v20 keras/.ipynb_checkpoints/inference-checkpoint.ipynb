{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import uff\n",
    "import tensorrt as trt\n",
    "import ctypes\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from six.moves import cPickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference(context, h_input, d_input, h_output, d_output, stream):\n",
    "    # Transfer input data to the GPU.\n",
    "    cuda.memcpy_htod_async(d_input, h_input, stream)\n",
    "    # Run inference.\n",
    "    inference_success = context.execute_async(bindings=[int(d_input), int(d_output)], stream_handle=stream.handle)\n",
    "    # Transfer predictions back from the GPU.\n",
    "    cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
    "    # Synchronize the stream\n",
    "    stream.synchronize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate host and device buffers, and create a stream.\n",
    "def allocate_buffers(engine):\n",
    "    # Determine dimensions and create page-locked memory buffers (i.e. won't be swapped to disk) to hold host inputs/outputs.\n",
    "    h_input = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(0)), dtype=trt.nptype(trt.float32))\n",
    "    h_output = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(1)), dtype=trt.nptype(trt.float32))\n",
    "    # Allocate device memory for inputs and outputs.\n",
    "    d_input = cuda.mem_alloc(h_input.nbytes)\n",
    "    d_output = cuda.mem_alloc(h_output.nbytes)\n",
    "    # Create a stream in which to copy inputs/outputs and run inference.\n",
    "    stream = cuda.Stream()\n",
    "    return h_input, d_input, h_output, d_output, stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR10_dataset(file_name):\n",
    "    with open(file_name, 'rb') as f:                \n",
    "        d = cPickle.load(f)\n",
    "        # decode utf8\n",
    "        d_decoded = {}\n",
    "        for k, v in d.items():\n",
    "            d_decoded[k.decode('utf8')] = v\n",
    "        d = d_decoded\n",
    "        data = d['data']\n",
    "        labels = d['labels']\n",
    "        raw_float_data = np.array(data, dtype=float) / 255.0\n",
    "        return raw_float_data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324.187404871\n"
     ]
    }
   ],
   "source": [
    "\n",
    "serialized_engine = \"fp32.engine\"\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.ERROR)\n",
    "with trt.Runtime(TRT_LOGGER) as runtime:\n",
    "    with open(serialized_engine, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "        h_input, d_input, h_output, d_output, stream = allocate_buffers(engine)\n",
    "        with engine.create_execution_context() as context:\n",
    "                file_name = \"/home/vtpc/Documents/Alvils/tensorrt/cifar-10-batches-py/test_batch\";\n",
    "                # Reshape the array to 4-dimensions.\n",
    "                imgs, labels = load_CIFAR10_dataset(file_name)\n",
    "                processed_imgs = imgs.reshape([-1, 3, 32, 32]).astype(trt.nptype(trt.float32)).ravel()\n",
    "                t0 = time.time()\n",
    "                for i in range(0, 1000000):\n",
    "                    np.copyto(h_input, processed_imgs[1])\n",
    "                    do_inference(context, h_input, d_input, h_output, d_output, stream)\n",
    "                t1 = time.time()     \n",
    "                total_t = t1-t0\n",
    "                \n",
    "                print(total_t)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
