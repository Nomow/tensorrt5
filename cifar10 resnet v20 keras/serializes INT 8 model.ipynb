{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import uff\n",
    "import tensorrt as trt\n",
    "import ctypes\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from six.moves import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/vtpc/Documents/Alvils/tensorrt/cifar-10-batches-py/test_batch\", 'rb') as f:\n",
    "                \n",
    "                \n",
    "    d = cPickle.load(f)\n",
    "    # decode utf8\n",
    "    d_decoded = {}\n",
    "    for k, v in d.items():\n",
    "        d_decoded[k.decode('utf8')] = v\n",
    "    d = d_decoded\n",
    "    data = d['data']\n",
    "    labels = d['labels']\n",
    "    raw_float = np.array(data, dtype=float) / 255.0\n",
    "    # Reshape the array to 4-dimensions.\n",
    "    images = raw_float.reshape([-1, 3, 32, 32])\n",
    "    \n",
    "    images_flatted = np.zeros((images.shape[0], images[0].ravel().shape[0]), dtype=np.float32)\n",
    "\n",
    "    \n",
    "    for i in range(0, len(images)):\n",
    "        images_flatted[i] = images[i].ravel()\n",
    "print(images_flatted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3, 32, 32)\n",
      "(500, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print((images[:500, :, :, :]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageBatchStream():\n",
    "    def __init__(self, batch_size, data):\n",
    "        self.batch_size = batch_size\n",
    "        self.max_batches = (len(data) // batch_size) + (1 if (len(data) % batch_size) else 0)\n",
    "        self.data = data\n",
    "        self.calibration_data = np.zeros((batch_size, 3072), dtype=np.float32)\n",
    "        self.batch = 0\n",
    "\n",
    "         \n",
    "    def reset(self):\n",
    "        self.batch = 0\n",
    "     \n",
    "    def next_batch(self):\n",
    "        if self.batch < self.max_batches:\n",
    "            batch_data = self.data[self.batch_size * self.batch : self.batch_size * (self.batch + 1)]\n",
    "            for i in range(len(batch_data)):\n",
    "                self.calibration_data[i] = batch_data[i]\n",
    "            self.batch += 1\n",
    "            return np.ascontiguousarray(self.calibration_data, dtype=np.float32)\n",
    "        else:\n",
    "            return np.array([])\n",
    "        \n",
    "class PythonEntropyCalibrator(trt.IInt8EntropyCalibrator):\n",
    "    def __init__(self, input_layers, stream):\n",
    "        trt.IInt8EntropyCalibrator.__init__(self)       \n",
    "        self.input_layers = input_layers\n",
    "        self.stream = stream\n",
    "        self.d_input = cuda.mem_alloc(self.stream.data.nbytes)\n",
    "        \n",
    "        stream.reset()\n",
    "\n",
    "    def get_batch_size(self):\n",
    "        return self.stream.batch_size\n",
    "\n",
    "    def get_batch(self, bindings, names):\n",
    "        batch = self.stream.next_batch()\n",
    "        if not batch.size:   \n",
    "            return None\n",
    "      \n",
    "        cuda.memcpy_htod(self.d_input, batch)\n",
    "        for i in self.input_layers[0]:\n",
    "            assert names[0] != i\n",
    "\n",
    "        bindings[0] = int(self.d_input)\n",
    "        return bindings\n",
    "\n",
    "    def read_calibration_cache(self, length):\n",
    "        return None\n",
    "\n",
    "    def write_calibration_cache(self, ptr, size):\n",
    "        cache = ctypes.c_char_p(str(ptr))\n",
    "        with open('calibration_cache.bin', 'wb') as f:\n",
    "            f.write(cache.value)\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## information about data needed to parse model and build engine\n",
    "class ModelData(object):\n",
    "    MODEL_FILE = \"/home/vtpc/Documents/Alvils/tensorrt/pretrained-models/cifar10_resnet20v1_model/model.pb\"\n",
    "    INPUT_NAME =\"input_1\"\n",
    "    INPUT_SHAPE = (3, 32, 32) # always nchw\n",
    "    OUTPUT_NAME = \"dense_1/Softmax\"\n",
    "    DTYPE = trt.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Automatically deduced input nodes ===\n",
      "[name: \"input_1\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "      dim {\n",
      "        size: -1\n",
      "      }\n",
      "      dim {\n",
      "        size: 32\n",
      "      }\n",
      "      dim {\n",
      "        size: 32\n",
      "      }\n",
      "      dim {\n",
      "        size: 3\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n",
      "=========================================\n",
      "\n",
      "Using output node dense_1/Softmax\n",
      "Converting to UFF graph\n",
      "DEBUG: convert reshape to flatten node\n",
      "No. nodes: 216\n"
     ]
    }
   ],
   "source": [
    "# tensorflow to uff\n",
    "uff_model = uff.from_tensorflow_frozen_model(ModelData.MODEL_FILE, [ModelData.OUTPUT_NAME])\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "NUM_IMAGES_PER_BATCH = 5\n",
    "Int8_calibrator = PythonEntropyCalibrator([ModelData.INPUT_NAME], ImageBatchStream(5, images_flatted[:500,:]))\n",
    "# parses model to trt\n",
    "with trt.Builder(TRT_LOGGER) as builder, builder.create_network() as network, trt.UffParser() as parser:\n",
    "    # builder argums for optimization\n",
    "    builder.int8_mode = True\n",
    "    builder.int8_calibrator = Int8_calibrator\n",
    "    builder.max_batch_size = 1\n",
    "    builder.max_workspace_size = 1 << 30    \n",
    "    # Parse the Uff Network\n",
    "    parser.register_input(ModelData.INPUT_NAME, ModelData.INPUT_SHAPE)#, trt.UffInputOrder.NHWC)\n",
    "    parser.register_output(ModelData.OUTPUT_NAME)\n",
    "    parsed = parser.parse_buffer(uff_model, network)\n",
    "    print(parsed)\n",
    "    # builds engine\n",
    "    with builder.build_cuda_engine(network) as engine:\n",
    "        with open(\"int8.engine\", \"wb\") as f:\n",
    "            f.write(engine.serialize())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
