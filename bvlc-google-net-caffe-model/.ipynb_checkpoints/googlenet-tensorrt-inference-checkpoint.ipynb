{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import uff\n",
    "import tensorrt as trt\n",
    "import ctypes\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from six.moves import cPickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "import caffe\n",
    "import skimage.transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_image(im, mean_val):\n",
    "    h, w, _ = im.shape\n",
    "    if h < w:\n",
    "        im = skimage.transform.resize(im, (224, w*224/h), preserve_range=True)\n",
    "    else:\n",
    "        im = skimage.transform.resize(im, (h*224/w, 224), preserve_range=True)\n",
    "    # Central crop to 224x224\n",
    "    h, w, _ = im.shape\n",
    "    im = im[h//2-112:h//2+112, w//2-112:w//2+112]      \n",
    "    #shuffle axes\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "    # convert to BGR\n",
    "    im = im[::-1, :, :]\n",
    "    # scales back to 0 ... 255 (caffe loads images as 0 ... 1)\n",
    "    im = im * 255.0\n",
    "    im = im - mean_val\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(engine, imgs):\n",
    "    with engine.create_execution_context() as context:\n",
    "        batch_size = engine.max_batch_size; \n",
    "        nb_of_imgs = len(imgs); \n",
    "        nb_of_batches = calculateNbOfBatches(batch_size, nb_of_imgs); \n",
    "        nb_of_predictions = 1000; # predictions per img\n",
    "        results = []\n",
    "        stream = cuda.Stream()\n",
    "        for i in range(0, nb_of_batches):\n",
    "            imgs_index = calculateImgIndicesToUseForInference(batch_size, nb_of_batches, i, nb_of_imgs);\n",
    "            current_batch_size = imgs_index[1] - imgs_index[0];\n",
    "            raveled_imgs = imgs[imgs_index[0] : imgs_index[1]].ravel();\n",
    "            \n",
    "            # Preallocated host and device data\n",
    "            output = np.empty(nb_of_predictions * current_batch_size, dtype = np.float32)\n",
    "            d_input = cuda.mem_alloc(1 * raveled_imgs.nbytes)\n",
    "            d_output = cuda.mem_alloc(1 * output.nbytes)\n",
    "            \n",
    "            # creates device binding to assign to inference\n",
    "            bindings=[d_input, d_output]\n",
    "            \n",
    "            #copies host image data to device array\n",
    "            cuda.memcpy_htod_async(d_input, raveled_imgs, stream)\n",
    "            \n",
    "            # inference\n",
    "            context.execute_async(bindings = bindings, stream_handle=stream.handle, batch_size = current_batch_size)\n",
    "            \n",
    "            # copies device output back to host output\n",
    "            cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    "            \n",
    "            #synchronizes stream before appending results\n",
    "            stream.synchronize()\n",
    "            \n",
    "            results = np.append(results, output)\n",
    "        return results.reshape(-1, nb_of_predictions)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vtpc/.local/lib/python2.7/site-packages/skimage/io/_io.py:49: UserWarning: `as_grey` has been deprecated in favor of `as_gray`\n",
      "  warn('`as_grey` has been deprecated in favor of `as_gray`')\n"
     ]
    }
   ],
   "source": [
    "# img loading\n",
    "img_load_count = 2000\n",
    "img_path = \"/home/vtpc/Documents/Alvils/tensorrt/data/ilsvrc12/imgs/\"\n",
    "img_names_and_labels_path = '/home/vtpc/Documents/Alvils/tensorrt/data/ilsvrc12/val.txt'\n",
    "imgs_file_names_and_labels = np.loadtxt(img_names_and_labels_path,  dtype=str)\n",
    "# img loading\n",
    "imgs = []\n",
    "labels = []\n",
    "for i in range(0, img_load_count):\n",
    "    imgs.append(caffe.io.load_image(img_path + imgs_file_names_and_labels[i][0]))\n",
    "    labels.append(imgs_file_names_and_labels[i][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "mean_values = np.array([104, 117, 123]).reshape((3,1,1))\n",
    "imgs_transformed = [];\n",
    "for img in imgs:\n",
    "    imgs_transformed.append(prep_image(img, mean_values))\n",
    "    \n",
    "imgs_raveled = np.zeros((img_load_count, 224 * 224 * 3), dtype= np.float32)\n",
    "for i in range(0, len(imgs_transformed)):\n",
    "    imgs_raveled[i] = imgs_transformed[i].ravel()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "Time without transfer: 0.0322749614716\n",
      "Time without transfer: 0.031848192215\n",
      "Time without transfer: 0.0318028926849\n",
      "Time without transfer: 0.0305640697479\n",
      "Time without transfer: 0.0290699005127\n",
      "Time without transfer: 0.0291080474854\n",
      "Time without transfer: 0.0290269851685\n",
      "Time without transfer: 0.0285038948059\n",
      "Time without transfer: 0.0281829833984\n",
      "Time without transfer: 0.0282139778137\n",
      "Time without transfer: 0.0289361476898\n",
      "Time without transfer: 0.0278789997101\n",
      "Time without transfer: 0.0277390480042\n",
      "Time without transfer: 0.00987792015076\n",
      "Time with transfer: 0.601088047028\n",
      "0.6755\n"
     ]
    }
   ],
   "source": [
    "trt_engine_path = \"int8.engine\"\n",
    "engine = loadEngine(trt_engine_path)\n",
    "inference(engine, imgs_raveled, labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
