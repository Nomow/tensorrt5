{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import caffe\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import uff\n",
    "import tensorrt as trt\n",
    "import ctypes\n",
    "import skimage.transform\n",
    "from matplotlib import pyplot as plt\n",
    "from six.moves import cPickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import os, os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_image(im, mean_val):\n",
    "    h, w, _ = im.shape\n",
    "    if h < w:\n",
    "        im = skimage.transform.resize(im, (224, w*224/h), preserve_range=True)\n",
    "    else:\n",
    "        im = skimage.transform.resize(im, (h*224/w, 224), preserve_range=True)\n",
    "\n",
    "    # Central crop to 224x224\n",
    "    h, w, _ = im.shape\n",
    "    im = im[h//2-112:h//2+112, w//2-112:w//2+112]\n",
    "        \n",
    "    #shuffle axes to c01\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "    \n",
    "    # convert to BGR\n",
    "    im = im[::-1, :, :]\n",
    "    # scaled back to 0 ... 255 (caffe loads images as 0 ... 1)\n",
    "    im = im * 255.0\n",
    "    im = im - mean_val\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageBatchStream():\n",
    "    def __init__(self, batch_size, data):\n",
    "        self.batch_size = batch_size\n",
    "        self.max_batches = (len(data) // batch_size) + (1 if (len(data) % batch_size) else 0)\n",
    "        self.data = data\n",
    "        self.calibration_data = np.zeros((batch_size, 224 * 224 * 3), dtype=np.float32)\n",
    "        self.batch = 0\n",
    "\n",
    "         \n",
    "    def reset(self):\n",
    "        self.batch = 0\n",
    "     \n",
    "    def next_batch(self):\n",
    "        if self.batch < self.max_batches:\n",
    "            batch_data = self.data[self.batch_size * self.batch : self.batch_size * (self.batch + 1)]\n",
    "            for i in range(len(batch_data)):\n",
    "                self.calibration_data[i] = batch_data[i]\n",
    "            self.batch += 1\n",
    "            return np.ascontiguousarray(self.calibration_data, dtype=np.float32)\n",
    "        else:\n",
    "            return np.array([])\n",
    "        \n",
    "class PythonEntropyCalibrator(trt.IInt8EntropyCalibrator):\n",
    "    def __init__(self, input_layers, stream):\n",
    "        trt.IInt8EntropyCalibrator.__init__(self)       \n",
    "        self.input_layers = input_layers\n",
    "        self.stream = stream\n",
    "        self.d_input = cuda.mem_alloc(self.stream.data.nbytes)\n",
    "        \n",
    "        stream.reset()\n",
    "\n",
    "    def get_batch_size(self):\n",
    "        return self.stream.batch_size\n",
    "\n",
    "    def get_batch(self, bindings, names):\n",
    "        batch = self.stream.next_batch()\n",
    "        if not batch.size:   \n",
    "            return None\n",
    "      \n",
    "        cuda.memcpy_htod(self.d_input, batch)\n",
    "        for i in self.input_layers[0]:\n",
    "            assert names[0] != i\n",
    "\n",
    "        bindings[0] = int(self.d_input)\n",
    "        return bindings\n",
    "\n",
    "    def read_calibration_cache(self, length):\n",
    "        return None\n",
    "\n",
    "    def write_calibration_cache(self, ptr, size):\n",
    "        cache = ctypes.c_char_p(str(ptr))\n",
    "        with open('calibration_cache.bin', 'wb') as f:\n",
    "            f.write(cache.value)\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## information about data needed to parse model and build engine\n",
    "class ModelData(object):\n",
    "    MODEL_FILE = \"/home/vtpc/Documents/Alvils/tensorrt/libs/caffe/models/bvlc_googlenet/weights.caffemodel\"\n",
    "    DEPLOY_FILE = \"/home/vtpc/Documents/Alvils/tensorrt/libs/caffe/models/bvlc_googlenet/deploy.prototxt\"\n",
    "    INPUT_SHAPE = (3, 224, 224) # always nchw\n",
    "    INPUT_NAME = \"data\"\n",
    "    OUTPUT_NAME = \"prob\"# 227 dim: 227\n",
    "    DTYPE = trt.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vtpc/.local/lib/python2.7/site-packages/skimage/io/_io.py:49: UserWarning: `as_grey` has been deprecated in favor of `as_gray`\n",
      "  warn('`as_grey` has been deprecated in favor of `as_gray`')\n",
      "/home/vtpc/.local/lib/python2.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/vtpc/.local/lib/python2.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "# img loading\n",
    "img_load_count = 1000\n",
    "img_path = \"/home/vtpc/Documents/Alvils/tensorrt/data/ilsvrc12/imgs/\"\n",
    "img_names_and_labels_path = '/home/vtpc/Documents/Alvils/tensorrt/data/ilsvrc12/val.txt'\n",
    "imgs_file_names_and_labels = np.loadtxt(img_names_and_labels_path,  dtype=str)\n",
    "# img loading\n",
    "imgs = []\n",
    "labels = []\n",
    "for i in range(0, img_load_count):\n",
    "    imgs.append(caffe.io.load_image(img_path + imgs_file_names_and_labels[i][0]))\n",
    "    labels.append(imgs_file_names_and_labels[i][1])\n",
    "\n",
    "# preprocess\n",
    "mean_values = np.array([104, 117, 123]).reshape((3,1,1))\n",
    "imgs_transformed = [];\n",
    "for img in imgs:\n",
    "    imgs_transformed.append(prep_image(img, mean_values))\n",
    "    \n",
    "imgs_raveled = np.zeros((1000, 224 * 224 * 3), dtype= np.float32)\n",
    "for i in range(0, len(imgs_transformed)):\n",
    "    imgs_raveled[i] = imgs_transformed[i].ravel()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorrt.tensorrt.IBlobNameToTensor object at 0x7f29e95326c0>\n"
     ]
    }
   ],
   "source": [
    "Int8_calibrator = PythonEntropyCalibrator([ModelData.INPUT_NAME], ImageBatchStream(5, imgs_raveled[:500,:]))\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "# parses model to trt\n",
    "with trt.Builder(TRT_LOGGER) as builder, builder.create_network() as network, trt.CaffeParser() as parser:\n",
    "    # builder argums for optimization\n",
    "    builder.int8_mode = True\n",
    "    builder.int8_calibrator = Int8_calibrator\n",
    "    builder.max_batch_size = 500\n",
    "    builder.max_workspace_size = 1 << 30    \n",
    "\n",
    "    # Load the Caffe model and parse it in order to populate the TensorRT network.\n",
    "    # This function returns an object that we can query to find tensors by name.\n",
    "    model_tensors = parser.parse(deploy=ModelData.DEPLOY_FILE, model=ModelData.MODEL_FILE, network=network, dtype=ModelData.DTYPE)\n",
    "    # For Caffe, we need to manually mark the output of the network.\n",
    "    # Since we know the name of the output tensor, we can find it in model_tensors.\n",
    "    print(model_tensors)\n",
    "    network.mark_output(model_tensors.find(ModelData.OUTPUT_NAME))\n",
    "\n",
    "    # builds engine\n",
    "    with builder.build_cuda_engine(network) as engine:\n",
    "        with open(\"int8.engine\", \"wb\") as f:\n",
    "            f.write(engine.serialize())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
