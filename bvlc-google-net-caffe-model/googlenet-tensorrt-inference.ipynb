{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import uff\n",
    "import tensorrt as trt\n",
    "import ctypes\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from six.moves import cPickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "import caffe\n",
    "import skimage.transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_image(im, mean_val):\n",
    "    h, w, _ = im.shape\n",
    "    if h < w:\n",
    "        im = skimage.transform.resize(im, (224, w*224/h), preserve_range=True)\n",
    "    else:\n",
    "        im = skimage.transform.resize(im, (h*224/w, 224), preserve_range=True)\n",
    "\n",
    "    # Central crop to 224x224\n",
    "    h, w, _ = im.shape\n",
    "    im = im[h//2-112:h//2+112, w//2-112:w//2+112]\n",
    "        \n",
    "    #shuffle axes to c01\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "    \n",
    "    # convert to BGR\n",
    "    im = im[::-1, :, :]\n",
    "    # scaled back to 0 ... 255 (caffe loads images as 0 ... 1)\n",
    "    im = im * 255.0\n",
    "    im = im - mean_val\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mAP(y_true, y_pred):\n",
    "    \n",
    "    y_true = np.array(y_true).astype(np.int64)\n",
    "    y_true = tf.identity(y_true)\n",
    "\n",
    "    y_pred = np.array(y_pred).astype(np.float32)\n",
    "    y_pred = tf.identity(y_pred) # np to tensor\n",
    "    _, m_ap = tf.metrics.average_precision_at_k(y_true, y_pred, 1)\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    tf_map = sess.run(m_ap)\n",
    "    return tf_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadEngine(trt_engine_file_path):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.ERROR)\n",
    "    with trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        with open(trt_engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "            engine = runtime.deserialize_cuda_engine(f.read())\n",
    "            return engine;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(engine, imgs, labels):\n",
    "    with engine.create_execution_context() as context:\n",
    "        batch_size = 150\n",
    "        print(batch_size)\n",
    "        stream = cuda.Stream()\n",
    "        # inference\n",
    "        max_batches = ((len(imgs_transformed) // batch_size) + (1 if (len(imgs_transformed) % batch_size) else 0))\n",
    "        results = []\n",
    "        current = 0\n",
    "        t0_with_transfer = time.time()   \n",
    "        imgs = np.asarray(imgs)\n",
    "        for i in range(0, max_batches):\n",
    "            current = i * batch_size;\n",
    "            next_ind = 0;\n",
    "            imgs_ravel = [];\n",
    "            if (i+1 == max_batches):\n",
    "                next_ind = i * batch_size  + len(imgs) - i * batch_size\n",
    "                imgs_ravel =  imgs[current : next_ind]\n",
    "            else:\n",
    "                next_ind = (i + 1) * batch_size                \n",
    "        \n",
    "            imgs_ravel = imgs[current : next_ind].ravel()\n",
    "            #print(imgs_ravel.shape)\n",
    "            current_batch_size = next_ind - current;\n",
    "            output = np.empty(1000 * current_batch_size, dtype = np.float32)\n",
    "            d_input = cuda.mem_alloc(1 * imgs_ravel.nbytes)\n",
    "            d_output = cuda.mem_alloc(1 * output.nbytes)\n",
    "            bindings=[d_input, d_output]\n",
    "            t0_without_transer = time.time()     \n",
    "            cuda.memcpy_htod_async(d_input, imgs_ravel, stream)\n",
    "            context.execute_async(bindings = bindings, stream_handle=stream.handle, batch_size = current_batch_size)\n",
    "            cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    "            stream.synchronize()\n",
    "            t1_without_transfer = time.time() \n",
    "            total_t_without_transfer = t1_without_transfer - t0_without_transer;\n",
    "            print(\"Time without transfer: \" + str(total_t_without_transfer))\n",
    "            results = np.append(results, output)\n",
    "        t1_with_transfer = time.time()\n",
    "        total_t_with_transfer = t1_with_transfer - t0_with_transfer;\n",
    "        print(\"Time with transfer: \" + str(total_t_with_transfer))\n",
    "        results_reshaped = results.reshape(-1, 1000)\n",
    "        precision = mAP(labels, results_reshaped)\n",
    "        print(precision)\n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vtpc/.local/lib/python2.7/site-packages/skimage/io/_io.py:49: UserWarning: `as_grey` has been deprecated in favor of `as_gray`\n",
      "  warn('`as_grey` has been deprecated in favor of `as_gray`')\n"
     ]
    }
   ],
   "source": [
    "# img loading\n",
    "img_load_count = 2000\n",
    "img_path = \"/home/vtpc/Documents/Alvils/tensorrt/data/ilsvrc12/imgs/\"\n",
    "img_names_and_labels_path = '/home/vtpc/Documents/Alvils/tensorrt/data/ilsvrc12/val.txt'\n",
    "imgs_file_names_and_labels = np.loadtxt(img_names_and_labels_path,  dtype=str)\n",
    "# img loading\n",
    "imgs = []\n",
    "labels = []\n",
    "for i in range(0, img_load_count):\n",
    "    imgs.append(caffe.io.load_image(img_path + imgs_file_names_and_labels[i][0]))\n",
    "    labels.append(imgs_file_names_and_labels[i][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "mean_values = np.array([104, 117, 123]).reshape((3,1,1))\n",
    "imgs_transformed = [];\n",
    "for img in imgs:\n",
    "    imgs_transformed.append(prep_image(img, mean_values))\n",
    "    \n",
    "imgs_raveled = np.zeros((img_load_count, 224 * 224 * 3), dtype= np.float32)\n",
    "for i in range(0, len(imgs_transformed)):\n",
    "    imgs_raveled[i] = imgs_transformed[i].ravel()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "Time without transfer: 0.0322749614716\n",
      "Time without transfer: 0.031848192215\n",
      "Time without transfer: 0.0318028926849\n",
      "Time without transfer: 0.0305640697479\n",
      "Time without transfer: 0.0290699005127\n",
      "Time without transfer: 0.0291080474854\n",
      "Time without transfer: 0.0290269851685\n",
      "Time without transfer: 0.0285038948059\n",
      "Time without transfer: 0.0281829833984\n",
      "Time without transfer: 0.0282139778137\n",
      "Time without transfer: 0.0289361476898\n",
      "Time without transfer: 0.0278789997101\n",
      "Time without transfer: 0.0277390480042\n",
      "Time without transfer: 0.00987792015076\n",
      "Time with transfer: 0.601088047028\n",
      "0.6755\n"
     ]
    }
   ],
   "source": [
    "trt_engine_path = \"int8.engine\"\n",
    "engine = loadEngine(trt_engine_path)\n",
    "inference(engine, imgs_raveled, labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
