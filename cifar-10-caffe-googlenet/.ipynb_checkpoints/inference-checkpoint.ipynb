{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vtpc/Documents/Alvils/tensorrt5\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import caffe\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import uff\n",
    "import tensorrt as trt\n",
    "import ctypes\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from six.moves import cPickle\n",
    "import time\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "logging.debug(\"test\")\n",
    "caffe.set_device(0) \n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = caffe.Net('/home/vtpc/Documents/Alvils/tensorrt/pretrained-models/cifar-10-googlenet/deploy.prototxt',\n",
    "                '/home/vtpc/Documents/Alvils/tensorrt/pretrained-models/cifar-10-googlenet/weights.caffemodel',\n",
    "                caffe.TEST)\n",
    "cifar_file = \"/home/vtpc/Documents/Alvils/tensorrt/data/cifar10/test_batch\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-subtracted values: [('B', 125.30691780149937), ('G', 122.9503942579031), ('R', 113.86538316309452)]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "mu = np.load( \"/home/vtpc/Documents/Alvils/tensorrt/pretrained-models/cifar-10-googlenet/mean.npy\" )\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "# create transformer for the input called 'data'\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "#transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR\n",
    "\n",
    "# load the mean ImageNet image (as distributed with Caffe) for subtraction\n",
    "#mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "print 'mean-subtracted values:', zip('BGR', mu)\n",
    "\n",
    "\n",
    "print(mu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "(10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 450\n",
    "imgs, labels = load_CIFAR10_dataset(cifar_file)\n",
    "transformed_imgs = imgs.reshape([-1, 3, 32, 32])\n",
    "transformed_imgs = np.transpose(transformed_imgs, (0, 2, 3, 1))\n",
    "print(transformed_imgs.shape)\n",
    "new_ims = np.zeros((10000, 3, 32, 32))\n",
    "for i in range(0, len(new_ims)):\n",
    "    new_ims[i] = transformer.preprocess('data', transformed_imgs[i])\n",
    "#print(\"a\")\n",
    "\n",
    "#new_ims = swapImgsChannels(new_ims)#.transpose([0, 3, 2, 1])#np.zeros((im_shape[0], im_shape[3], im_shape[2], im_shape[1]))\n",
    "#plt.imshow(np.transpose(new_ims[15],(1,2,0)))\n",
    "#for i in range(0, len(new_ims)):\n",
    "#    new_ims[i][0] = new_ims[i][0] - mu[0]\n",
    "#    new_ims[i][1] = new_ims[i][1] - mu[1]\n",
    "#    new_ims[i][2] = new_ims[i][2] - mu[2]\n",
    "\n",
    "#plt.imshow(np.transpose(new_ims[15],(1,2,0)))\n",
    "\n",
    "#for i in range(0, len(transformed_imgs)):\n",
    "#    new_ims[i] = transformer.preprocess('data', transformed_imgs[i])\n",
    "#print(\"a\")\n",
    "print(new_ims.shape)\n",
    "max_batches = ((len(transformed_imgs) // batch_size) + (1 if (len(transformed_imgs) % batch_size) else 0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 0.598937988281\n",
      "0.7891\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "current = 0\n",
    "\n",
    "\n",
    "t0 = time.time()     \n",
    "for i in range(0, max_batches):\n",
    "    current = i * batch_size;\n",
    "    next_ind = 0;\n",
    "    imgs_ravel = [];\n",
    "    if (i+1 == max_batches):\n",
    "        next_ind = i * batch_size  + len(new_ims) - i * batch_size\n",
    "    else:\n",
    "        next_ind = (i + 1) * batch_size\n",
    "    current_batch_size = next_ind - current;\n",
    "    imgs_ravel = new_ims[current : next_ind]    \n",
    "    net.blobs['data'].reshape(current_batch_size, 3, 32, 32)\n",
    "    for j in range(0, current_batch_size):\n",
    "        net.blobs['data'].data[j,:,:,:] = imgs_ravel[j]\n",
    "    output = net.forward()\n",
    "    results = np.append(results, output['prob'])\n",
    "t1 = time.time()\n",
    "time_total = t1 - t0;\n",
    "print(\"total time: \" + str(time_total))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = results.reshape(-1, 10)\n",
    "pred = mAP(labels, results)\n",
    "print(pred)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
