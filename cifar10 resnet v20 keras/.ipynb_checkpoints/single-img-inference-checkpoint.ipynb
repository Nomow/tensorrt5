{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sample uses a UFF MNIST model to create a TensorRT Inference Engine\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "# This import causes pycuda to automatically manage CUDA context creation and cleanup.\n",
    "import pycuda.autoinit\n",
    "import uff\n",
    "import tensorrt as trt\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from six.moves import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## information about data needed to parse model and build engine\n",
    "class ModelData(object):\n",
    "    MODEL_FILE = \"/home/vtpc/Documents/Alvils/tensorrt/pretrained-models/cifar10_resnet20v1_model/model.pb\"\n",
    "    INPUT_NAME =\"input_1\"\n",
    "    INPUT_SHAPE = (3, 32, 32) # always nchw\n",
    "    OUTPUT_NAME = \"dense_1/Softmax\"\n",
    "    DTYPE = trt.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate host and device buffers, and create a stream.\n",
    "def allocate_buffers(engine):\n",
    "    # Determine dimensions and create page-locked memory buffers (i.e. won't be swapped to disk) to hold host inputs/outputs.\n",
    "    h_input = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(0)), dtype=trt.nptype(ModelData.DTYPE))\n",
    "    h_output = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(1)), dtype=trt.nptype(ModelData.DTYPE))\n",
    "    # Allocate device memory for inputs and outputs.\n",
    "    d_input = cuda.mem_alloc(h_input.nbytes)\n",
    "    d_output = cuda.mem_alloc(h_output.nbytes)\n",
    "    # Create a stream in which to copy inputs/outputs and run inference.\n",
    "    stream = cuda.Stream()\n",
    "    return h_input, d_input, h_output, d_output, stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference(context, h_input, d_input, h_output, d_output, stream):\n",
    "    # Transfer input data to the GPU.\n",
    "    cuda.memcpy_htod_async(d_input, h_input, stream)\n",
    "    # Run inference.\n",
    "    inference_success = context.execute_async(bindings=[int(d_input), int(d_output)], stream_handle=stream.handle)\n",
    "    print(\"inference success: \" + str(inference_success))\n",
    "    # Transfer predictions back from the GPU.\n",
    "    cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
    "    # Synchronize the stream\n",
    "    stream.synchronize()\n",
    "    #print(\"========= h_input======\")\n",
    "    #print(h_input)\n",
    "    #print(\"========= d_input======\")\n",
    "    #print(d_input)\n",
    "   # print(\"========= h_output======\")\n",
    "    print((h_output))  \n",
    "   # print(\"========= d_output======\")\n",
    "   # print(d_output)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Automatically deduced input nodes ===\n",
      "[name: \"input_1\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "      dim {\n",
      "        size: -1\n",
      "      }\n",
      "      dim {\n",
      "        size: 32\n",
      "      }\n",
      "      dim {\n",
      "        size: 32\n",
      "      }\n",
      "      dim {\n",
      "        size: 3\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n",
      "=========================================\n",
      "\n",
      "Using output node dense_1/Softmax\n",
      "Converting to UFF graph\n",
      "DEBUG: convert reshape to flatten node\n",
      "No. nodes: 216\n"
     ]
    }
   ],
   "source": [
    "uff_model = uff.from_tensorflow_frozen_model(ModelData.MODEL_FILE, [ModelData.OUTPUT_NAME])\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed True\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(3, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48235294 0.47843137 0.47843137 ... 0.654902   0.63529414 0.6156863 ]\n",
      "inference success: True\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "aaaa\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For more information on TRT basics, refer to the introd samples.\n",
    "with trt.Builder(TRT_LOGGER) as builder, builder.create_network() as network, trt.UffParser() as parser:\n",
    "    # builder argums for optimization\n",
    "    builder.max_batch_size = 1\n",
    "    builder.max_workspace_size = 1 << 30\n",
    "    builder.fp16_mode = True\n",
    "    \n",
    "    # Parse the Uff Network\n",
    "    parser.register_input(ModelData.INPUT_NAME, ModelData.INPUT_SHAPE)#, trt.UffInputOrder.NHWC)\n",
    "    parser.register_output(ModelData.OUTPUT_NAME)\n",
    "    parsed = parser.parse_buffer(uff_model, network)\n",
    "    print(\"parsed \" + str(parsed))\n",
    "    # builds engine\n",
    "    with builder.build_cuda_engine(network) as engine:\n",
    "        h_input, d_input, h_output, d_output, stream = allocate_buffers(engine)\n",
    "        print((h_output))  \n",
    "\n",
    "        with engine.create_execution_context() as context:\n",
    "            with open(\"/home/vtpc/Documents/Alvils/tensorrt/cifar-10-batches-py/test_batch\", 'rb') as f:\n",
    "                \n",
    "                \n",
    "                d = cPickle.load(f)\n",
    "                # decode utf8\n",
    "                d_decoded = {}\n",
    "                for k, v in d.items():\n",
    "                    d_decoded[k.decode('utf8')] = v\n",
    "                d = d_decoded\n",
    "                data = d['data']\n",
    "                labels = d['labels']\n",
    "                raw_float = np.array(data, dtype=float) / 255.0\n",
    "                # Reshape the array to 4-dimensions.\n",
    "                images = raw_float.reshape([-1, 3, 32, 32])\n",
    "                # Reorder the indices of the array to have channels in the last axis\n",
    "                #images1 = images.transpose([0, 2, 3, 1])\n",
    "      \n",
    "\n",
    "                img = np.asarray(images[159]).astype(trt.nptype(ModelData.DTYPE))\n",
    "                print(img.shape)\n",
    "        \n",
    "                plt.imshow(img.transpose([1, 2, 0]))\n",
    "                plt.show()\n",
    "                single_img_flatten = img.ravel()\n",
    "                print(single_img_flatten)\n",
    "                #print(single_img_flatten.shape)\n",
    "                ##print(img.shape)\n",
    "                np.copyto(h_input, single_img_flatten)\n",
    "                do_inference(context, h_input, d_input, h_output, d_output, stream)\n",
    "                print(\"aaaa\")\n",
    "                print(np.argmax(h_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(engine.get_binding_shape(0))\n",
    "    print(\"aaa\\n\")\n",
    "    print(engine.get_binding_shape(1))\n",
    "    print(\"bbb \\n\")\n",
    "    print(trt.volume(engine.get_binding_shape(0)))\n",
    "    print(\"cccc\\n\")\n",
    "    print(trt.volume(engine.get_binding_shape(1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/home/vtpc/Documents/Alvils/tensorrt/cifar-10-batches-py/test_batch\") as f:\n",
    "    data = pickle.load(f)\n",
    "    for key in data:\n",
    "        print \"key: %s ,\" % (key)\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
